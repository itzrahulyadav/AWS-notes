# Object storage (Detailed Notes)

### Different type of storages

1.  Block Storage
      -  The storage is divided into small bits or bytes called blocks which have unique identifier.
      -  whenever any change is made instead of updating the entire storage,only the specific block
         is updated because of which this type of storages are very fast
      
      -  This are used for databases like relational database where individual pieces of file can be modified.

2.  File Storage
     -  This type of storage organizes the data into hierarichal manner into files and folders.
     -  Storage is divided into files,folders or directories and sub-directories.
   
3.  Object Storage
    -  The data called object is stored in flat structure called bucket.
    -  The key name prefixes,metadata and delimiters are used to organize data.

## Amazon S3(The infinite storage)
- AWS s3 is an object storage that can store virtually unlimited data into buckets.

#### Buckets

-  Buckets are containers that store objects.
-  1 - 100 buckets can be created per account,can be increased to 1000.
-  Features of buckets
    - buckets are owned by account and can't be transferred to other account.
    - buckets names are globally unique
    - buckets can't be renamed
    - bucket nesting is not allowed,unlimited objects can be stored
    - Conventions for naming buckets
           - names can be 3-63 chars long
           - can only contain lowercase letters,dots and hyphens (-)
           - start with lowercase letter or number
           - can't begin with xn--
           - not be formatted as IP address
           - only use dot if you are using the bucket for static site hosting.
          
 
 #### Introduction to objects

 - Objects are files and the metadata that describes the file.
 -  Max object size can be 5TB
 -  The key name uniquely identifies the object in the bucket. 
 -  Multiple variants of the object can be kept in the bucket using versioning.
              - Versioning is used to prevent unintended deletes
              - AWS provides unique version ID to each object uploaded.
 -  Value is the size of the object.
 -  Aws maintains object metadata such as creation date,size etc.
 -  Access to objects can be done using ACL and bucket policies.
 -  Tagging can be used to organize data
            -  A tag is a label that you assign to an AWS resource
            -  Tags consist of key and value pairs.
            -  Tags can be assigned to objects and buckets
            -  Max of 10 tags can be assigned to objects.    

#### Interacting with aws s3

-  We can interact with s3 using following ways:

      -  AWS management console:
            -  GUI view of s3
            -  maximum file size that can be uploaded are 160GB
      -   AWS CLI:
            -  used to manage buckets and objects using command Line
            -  operations can be performed using commands
      -   AWS SDK:
            -  allows us to manage s3 using programming languages
            -  uses s3 api to send requests

-  s3 supports REST API allowing us to perform CRUD operations using http requests.

-  AWS s3 supports two types of addressing models:
   1.  path style urls:

       - In this type bucket name comes after the region
       - <img src = "https://user-images.githubusercontent.com/65400893/219932140-1f962556-c325-485e-b5bf-0d78daa1f805.jpg" />

   2.  Virtual hosted-style urls:

       - Virtual hosting is the practice of serving multiple websites from a single web server.
       - Here bucket name is the part of domain name in the URL
       - <img src = "https://user-images.githubusercontent.com/65400893/219932256-289d8925-2124-4070-be3a-e966f8b76511.jpg"/>

#### s3 data management

-  aws s3 supports read-after-write consistency for any request object.

#### Using the command line

- s3 supports two types of commands
   - High level commands
   - low level commands
        - uses s3api command sets

for more detailed info refer to cli notes üëâüèª [here](https://github.com/itzrahulyadav/AWS-notes/tree/main/AWS_CLI/s3)


#### multi-part upload

-  we can upload or copy objects of upto 5GB in a single operation.To upload objects greater than that we can use __aws s3 multi part upload__.

-  <img src = "https://user-images.githubusercontent.com/65400893/219933222-e5de2598-7c97-445c-909d-0b035d625a12.png" width = "400px" height = "300px" />


##### Delete operations

- If versioning is not enabled the objects are deleted permanently.
- If versioning is enabled we can either delete objects permanently or put a delete marker on the specific version.


### cloud data migration services

AWS offers a wide variety of services to transfer your data in and out of the cloud

1.  Online data transfer services
    -  AWS datasync (Moves large amounts of data online between on premises and Amazon S3)
    -  AWS transfer family (Supports SFTP, FTPS)
    -  AWS s3 transfer acceleration (Secure transfers of files over long distances)
    -  AWS kinesis data firehose (Near-real-time analytics with the business intelligence)
    -  AWS kinesis data streams (Continuously captures and stores TBs of data per hour.)
    -  Amazon partner network (Continuously captures and stores TBs of data per hour.)
    
![H9CkKCD4wDQ02bWV_ADD9vmnNej-vrx_w-_NOPROCESS_datasync](https://user-images.githubusercontent.com/65400893/219933888-4b0890ea-486a-41fb-bdac-41e751f77d02.jpg)

2.  Offline data transfer services
    -  AWS snowcone
        - smallest member of snow family
        - has 8TB of storage
        - supports edge computing
        - can also use datasync to transfer data using edge computing

    -  AWS snowball
       - AWS Snowball is an edge computing, data migration, and edge storage device that comes in two options: Snowball Edge Storage Optimized and Snowball Edge Compute optimized.
       - storage optimised provides both block and object storage with 40vcpus
       - edge optimised provides 52vcpus and GPU
       
    -  AWS snowmobile
       - AWS Snowmobile is an Exabyte-scale data transfer service used to move extremely large amounts of data to AWS.
       - can transfer upto 100PB of data/truck

 3.  Hybrid data transfer services
     - AWS direct connect
       - AWS Direct Connect is a dedicated network connection from your on-premise data center to AWS.
       - It provides a dedicated connection for higher throughput and secure data transfer without passing through the internet
     - AWS storage gateway
       - can be used to store your on premises data in an existing Amazon S3 bucket. 
       - uses NFS and SMB
       -  You can transfer your data using an AWS File Storage Gateway over the internet or over an AWS Direct Connect connection.
 

### Secure your s3 buckets

-  By default s3 buckets are private and only the account owner can modify or view the buckets.
-  There are following access management features in s3 buckets
     - AWS IAM
     - Bucket Policies
     - Pre-Signed URLs
     - Access control lists

####  Advance s3 security features

-  Block public access
     - It blocks all the public access


Access policies describe who has access to what resouces.These are attached to the resources and are called resource policies.

Resource policies are attached to the resources for example: bucket policies,acls etc
User-based policies are attached to the users for example: an IAM policy or access policies

#### Bucket policies

-  Bucket policies are used to grant other AWS accounts or IAM users access to the bucket and the objects.
-  Bucket policies must have a "principal" key which donates entity (which is an account, user, role, or service) to whom the policy
  is granting access.
  
-  max size limit is 20 kb

#### Encryption in s3

- Data in transit(Data moving to and from the s3)
       -  The data in transit can be protected using SSL/TLS encryption.
       -  Can also use client side encryption

- For data in rest aws supports two types of options

1. Server Side Encryption 

- Amazon S3 encrypts an object before saving it to disk and decrypts it when you download it.
- Three server side encryption methods are:

*  SSE-S3
       -   Each object is encrypted with unique key.
       -   As an additional safeguard, it encrypts the key itself with a master key that it regularly rotates.

*  SSE-KMS
       -   similar to SSE-S3, but with some additional benefits and charges for using this service
       -   CMKs (Customer managed keys) are stored in AWS key management service (SSE-KMS)
       -   you can decide who can use cmks 
       -   also provide audit trail about use of cmk

*  SSE-C
      -  you manage the encryption keys and Amazon S3 manages the encryption
      -  the customer is responsible for managing and rotating the keys

2. Client Side Encryption

-  Client-side encryption is the act of encrypting sensitive data before sending it to Amazon S3.
-  We have two options 
      -  Use a CMK
      -  Use a master key and store it in your application.

#### AWS Datalake

-  A data lake is a centralized repository that allows you to migrate, store, and manage all structured and unstructured data at an unlimited scale. Once the data is centralized, you can extract value and gain insights from your data through analytics and machine learning.

-  A data lake makes the data and the analytics tools available to more of your users, across more lines of business enabling them to get the business insights they need, whenever they need them.

##### Data Cataloging

-  The data catalog provides a query-able interface of all assets stored in the data lake‚Äôs S3 buckets. The design of the data catalog is to provide a single source of truth about the contents of the data lake. 
-  AWS Glue
        -  Its a managed ETL (Extract,transform and load) service
        -  used for categorizing the data in data warehouse or data lake.

#### In place querying

-  Amazon Athena and Amazon Redshift Spectrum provide the in-place querying capabilities of an Amazon S3 data lake.
-  Amazon athena

          -  Amazon Athena is an interactive query service that makes it easy for you to analyze data directly in Amazon S3, using standard SQL. You can get results in a matter of seconds.
          -  Athena is serverless, so there is no infrastructure to set up or manage. You only pay for the volume of data assets scanned during the queries you run.

-  Amazon Redshift Spectrum
        -   Amazon Redshift is a large-scale, managed data warehouse service used with data assets in Amazon S3. However, data assets must be loaded into Amazon Redshift before queries run. 


-  You would typically use Athena for ad hoc data discovery and SQL querying, and then use Redshift Spectrum for more complex queries and scenarios where a large number of data lake users want to run concurrent BI and reporting workloads.

-  Amazon FSx for Lustre, is a fully managed file system that is optimized for compute-intensive workloads, such as high performance computing, machine learning, and media data processing workflows.

-  Amazon FSx for Lustre can use Amazon S3 as a raw data repository as well as a repository for processed data. It makes it easy to process your cloud datasets in Amazon S3.


#### AWS s3 storage classes deep archieve

-  S3 data is replicated across 3 or more azs in a single region
-  S3 has a flat non-hierarchical structure but we can use prefix to visualize a folder structure.
-  we can add upto 10 tags to each object to track and monitor cost and organize our data.
-  we can use lifecycle management rules to move data between different storage classes.

##### AWS S3 inventory reports

To keep track of objects and their respective tags, buckets, and prefixes, you can use an S3 inventory report that lists your stored objects within an S3 bucket or with a specific prefix, and their respective metadata and encryption status.

We can use athena and redshift spectrum to analyze the data stored in s3.

##### storage class analysis 

With storage class analysis, you can analyze storage access patterns and transition the right data to the right storage class. This feature observes data access patterns to to help you determine when to transition to storage classes more appropriate for less frequently accessed data. 
